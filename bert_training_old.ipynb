{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformers import BertTokenizer, BertForPreTraining, Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "HIDDEN_SIZE = 64\n",
    "VOCAB_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from transformers.tokenization_utils import AddedToken, PreTrainedTokenizer\n",
    "\"\"\"\n",
    "https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/canine/tokenization_canine.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "PAD = 0\n",
    "CLS = 1\n",
    "SEP = 2\n",
    "BOS = 3\n",
    "MASK = 4\n",
    "RESERVED = 5\n",
    "UNK = 6\n",
    "# the first keycode starts with 8\n",
    "\n",
    "SPECIAL_CODEPOINTS: Dict[int, str] = {\n",
    "    CLS: \"[CLS]\",\n",
    "    SEP: \"[SEP]\",\n",
    "    BOS: \"[BOS]\",\n",
    "    MASK: \"[MASK]\",\n",
    "    PAD: \"[PAD]\",\n",
    "    RESERVED: \"[RESERVED]\",\n",
    "    UNK: \"[UNK]\",\n",
    "}\n",
    "\n",
    "SPECIAL_CODEPOINTS_BY_NAME: Dict[str, int] = {name: codepoint for codepoint, name in SPECIAL_CODEPOINTS.items()}\n",
    "\n",
    "\n",
    "class KeysTokenizer(PreTrainedTokenizer):\n",
    "    r\"\"\"\n",
    "    Construct a CANINE tokenizer (i.e. a character splitter). It turns text into a sequence of characters, and then\n",
    "    converts each character into its Unicode code point.\n",
    "\n",
    "    [`CanineTokenizer`] inherits from [`PreTrainedTokenizer`].\n",
    "\n",
    "    Refer to superclass [`PreTrainedTokenizer`] for usage examples and documentation concerning parameters.\n",
    "\n",
    "    Args:\n",
    "        model_max_length (`int`, *optional*, defaults to 2048):\n",
    "                The maximum sentence length the model accepts.\n",
    "    \"\"\"\n",
    "\n",
    "    max_model_input_sizes = 128\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        add_prefix_space=False,\n",
    "        model_max_length=2048,\n",
    "        **kwargs\n",
    "    ):\n",
    "        bos_token = AddedToken(\"[BOS]\", lstrip=False, rstrip=False)\n",
    "        eos_token = AddedToken(\"[SEP]\", lstrip=False, rstrip=False)\n",
    "        sep_token = AddedToken(\"[SEP]\", lstrip=False, rstrip=False)\n",
    "        cls_token = AddedToken(\"[CLS]\", lstrip=False, rstrip=False)\n",
    "        pad_token = AddedToken(\"[PAD]\", lstrip=False, rstrip=False)\n",
    "        mask_token = AddedToken(\"[MASK]\", lstrip=False, rstrip=False)\n",
    "        unk_token = AddedToken(\"[UNK]\", lstrip=False, rstrip=False)\n",
    "\n",
    "        super().__init__(\n",
    "            bos_token=bos_token,\n",
    "            eos_token=eos_token,\n",
    "            sep_token=sep_token,\n",
    "            cls_token=cls_token,\n",
    "            pad_token=pad_token,\n",
    "            mask_token=mask_token,\n",
    "            unk_token=unk_token,\n",
    "            add_prefix_space=add_prefix_space,\n",
    "            model_max_length=model_max_length,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self) -> int:\n",
    "        return 256\n",
    "    \n",
    "    def get_vocab(self) -> Dict[str, int]:\n",
    "        vocab = {ch: key for key, ch in readable_keymap.items()}\n",
    "        vocab.update(self.added_tokens_encoder)\n",
    "        return vocab\n",
    "\n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokenize a string (i.e. perform character splitting).\"\"\"\n",
    "        return list(text)\n",
    "\n",
    "    def _convert_token_to_id(self, token: str) -> int:\n",
    "        \"\"\"Converts a token (i.e. a Unicode character) in an id (i.e. its integer Unicode code point value).\"\"\"\n",
    "        try:\n",
    "            return ord(token)\n",
    "        except TypeError:\n",
    "            raise ValueError(f\"invalid token: '{token}'\")\n",
    "\n",
    "    def _convert_id_to_token(self, index: int) -> str:\n",
    "        \"\"\"\n",
    "        Converts a id in a token (str). In case it's a special code point, convert to\n",
    "        human-readable format.\n",
    "        \"\"\"\n",
    "        if index in SPECIAL_CODEPOINTS:\n",
    "            return SPECIAL_CODEPOINTS[index]\n",
    "        if index in readable_keymap:\n",
    "            return readable_keymap[index]\n",
    "        raise ValueError(f\"invalid id: '{index}'\")\n",
    "\n",
    "    def convert_tokens_to_string(self, tokens):\n",
    "        return \"\".join(tokens)\n",
    "\n",
    "    def build_inputs_with_special_tokens(\n",
    "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and\n",
    "        adding special tokens. A CANINE sequence has the following format:\n",
    "\n",
    "        - single sequence: `[CLS] X [SEP]`\n",
    "        - pair of sequences: `[CLS] A [SEP] B [SEP]`\n",
    "\n",
    "        Args:\n",
    "            token_ids_0 (`List[int]`):\n",
    "                List of IDs to which the special tokens will be added.\n",
    "            token_ids_1 (`List[int]`, *optional*):\n",
    "                Optional second list of IDs for sequence pairs.\n",
    "\n",
    "        Returns:\n",
    "            `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.\n",
    "        \"\"\"\n",
    "        sep = [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "\n",
    "        result = cls + token_ids_0 + sep\n",
    "        if token_ids_1 is not None:\n",
    "            result += token_ids_1 + sep\n",
    "        return result\n",
    "\n",
    "    def get_special_tokens_mask(\n",
    "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding\n",
    "        special tokens using the tokenizer `prepare_for_model` method.\n",
    "\n",
    "        Args:\n",
    "            token_ids_0 (`List[int]`):\n",
    "                List of IDs.\n",
    "            token_ids_1 (`List[int]`, *optional*):\n",
    "                Optional second list of IDs for sequence pairs.\n",
    "            already_has_special_tokens (`bool`, *optional*, defaults to `False`):\n",
    "                Whether or not the token list is already formatted with special tokens for the model.\n",
    "\n",
    "        Returns:\n",
    "            `List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n",
    "        \"\"\"\n",
    "        if already_has_special_tokens:\n",
    "            return super().get_special_tokens_mask(\n",
    "                token_ids_0=token_ids_0, token_ids_1=token_ids_1, already_has_special_tokens=True\n",
    "            )\n",
    "\n",
    "        result = [1] + ([0] * len(token_ids_0)) + [1]\n",
    "        if token_ids_1 is not None:\n",
    "            result += ([0] * len(token_ids_1)) + [1]\n",
    "        return result\n",
    "\n",
    "    def create_token_type_ids_from_sequences(\n",
    "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Create a mask from the two sequences passed to be used in a sequence-pair classification task. A CANINE\n",
    "        sequence pair mask has the following format:\n",
    "\n",
    "        ```\n",
    "        0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
    "        | first sequence    | second sequence |\n",
    "        ```\n",
    "\n",
    "        If `token_ids_1` is `None`, this method only returns the first portion of the mask (0s).\n",
    "\n",
    "        Args:\n",
    "            token_ids_0 (`List[int]`):\n",
    "                List of IDs.\n",
    "            token_ids_1 (`List[int]`, *optional*):\n",
    "                Optional second list of IDs for sequence pairs.\n",
    "\n",
    "        Returns:\n",
    "            `List[int]`: List of [token type IDs](../glossary#token-type-ids) according to the given sequence(s).\n",
    "        \"\"\"\n",
    "        sep = [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "\n",
    "        result = len(cls + token_ids_0 + sep) * [0]\n",
    "        if token_ids_1 is not None:\n",
    "            result += len(token_ids_1 + sep) * [1]\n",
    "        return result\n",
    "\n",
    "    # CanineTokenizer has no vocab file\n",
    "    def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None):\n",
    "        return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/pupa/dev/kaggle/kvc/bert_training.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, i) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mtensor]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexamples[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m KvcDataset(\u001b[39m'\u001b[39;49m\u001b[39mdesktop\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, KeysTokenizer(), MAX_LENGTH)\n",
      "\u001b[1;32m/home/pupa/dev/kaggle/kvc/bert_training.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         train_data\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m'\u001b[39m: KvcDataset\u001b[39m.\u001b[39mpreprocess(session),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: user\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     })\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# TODO remove me!\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m batch_encoding \u001b[39m=\u001b[39m tokenizer(train_data, add_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49mblock_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexamples \u001b[39m=\u001b[39m batch_encoding[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexamples \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mtensor(e, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)} \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexamples]\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2806\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2805\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2806\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2807\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2808\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2864\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2861\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2863\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2864\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2867\u001b[0m     )\n\u001b[1;32m   2869\u001b[0m \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2870\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2873\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "class KvcDataset(Dataset):\n",
    "    @staticmethod\n",
    "    def preprocess(sample):\n",
    "        data = sample\n",
    "        data[:, :2] = (data[:, :2] - data[0][0])\n",
    "        duration = np.abs(data[:, 1] - data[:, 0])  # fix duration of keypress. ~349 items are broken\n",
    "        diff_press = np.diff(data[:, 0], prepend=data[0, 0])\n",
    "        data = np.column_stack((diff_press, duration, data[:, 2]))\n",
    "        return data\n",
    "\n",
    "    def __init__(self, scenario: str, split: str, tokenizer: KeysTokenizer, block_size: int):\n",
    "        \n",
    "        if split == 'train':\n",
    "            filename = f'{scenario}/{scenario}_dev_set.npy'\n",
    "        else:\n",
    "            assert split == 'test'\n",
    "            filename = f'{scenario}/{scenario}_test_sessions.npy'\n",
    "        assert os.path.isfile(filename), f\"Input file path {filename} not found\"\n",
    "\n",
    "        raw_data = np.load(filename, allow_pickle=True).item()\n",
    "        train_data = []\n",
    "        for user, sessions in raw_data.items():\n",
    "            for _, session in sessions.items():\n",
    "                train_data.append({\n",
    "                    'keys': KvcDataset.preprocess(session),\n",
    "                    'label': user\n",
    "            })\n",
    "            break  # TODO remove me!\n",
    "\n",
    "        batch_encoding = tokenizer(train_data, add_special_tokens=True, truncation=True, max_length=block_size)\n",
    "        self.examples = batch_encoding[\"input_ids\"]\n",
    "        self.examples = [{\"input_ids\": torch.tensor(e, dtype=torch.long)} for e in self.examples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.tensor]:\n",
    "        return self.examples[i]\n",
    "    \n",
    "train_dataset = KvcDataset('desktop', 'train', KeysTokenizer(), MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pupa/dev/kaggle/kvc/bert_training.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./bert_finetuned\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     overwrite_output_dir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     save_total_limit\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Define the Trainer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/transformers/trainer.py:342\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m args\n\u001b[1;32m    341\u001b[0m \u001b[39m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m enable_full_determinism(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mseed) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mfull_determinism \u001b[39melse\u001b[39;00m set_seed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mseed)\n\u001b[1;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhp_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/transformers/trainer_utils.py:95\u001b[0m, in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     93\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(seed)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 95\u001b[0m     torch\u001b[39m.\u001b[39;49mmanual_seed(seed)\n\u001b[1;32m     96\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmanual_seed_all(seed)\n\u001b[1;32m     97\u001b[0m     \u001b[39m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmanual_seed_all(seed)\n\u001b[1;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/cuda/random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    121\u001b[0m         default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    122\u001b[0m         default_generator\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 124\u001b[0m _lazy_call(cb, seed_all\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_lazy_call\u001b[39m(\u001b[39mcallable\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 229\u001b[0m         \u001b[39mcallable\u001b[39;49m()\n\u001b[1;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[39m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[39m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    233\u001b[0m         \u001b[39m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         \u001b[39mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/cuda/random.py:122\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[1;32m    121\u001b[0m     default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 122\u001b[0m     default_generator\u001b[39m.\u001b[39;49mmanual_seed(seed)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, LineByLineTextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "import string\n",
    "tokenizer = transformers.CanineTokenizer(model_max_length=128)\n",
    "model = transformers.MobileBertForMaskedLM(transformers.MobileBertConfig())\n",
    "\n",
    "# Load the dataset\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"/media/pupa/DataStorage/datasets/tinyshakespeare.txt\",\n",
    "    block_size=128,\n",
    ")\n",
    "\n",
    "class MyDataCollatorForLanguageModeling(DataCollatorForLanguageModeling):\n",
    "    # passthrough constructor\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        res = super().__call__(features, return_tensors)\n",
    "        return res\n",
    "\n",
    "# Define the data collator\n",
    "data_collator = MyDataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=256,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=2,\n",
    "    intermediate_size=128,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=MAX_LENGTH,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    pad_token_id=0,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    classifier_dropout=None,\n",
    "    is_decoder=False,\n",
    "    add_cross_attention=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForPreTraining(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2026, 3899, 2003, 10140, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello, my dog is cute [SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pupa/dev/kaggle/kvc/bert_training.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mforward(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39mchar_embeddings(inputs[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pupa/dev/kaggle/kvc/bert_training.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/dev/kaggle/kvc/.venv/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "model.forward(\n",
    "    inputs_embeds=char_embeddings(inputs[\"input_ids\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
